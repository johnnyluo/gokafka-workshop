Kafka And Go
Use kafka in golang microservice
07 Aug 2018

Johnny Luo
Platform
Campaign Monitor
johnnyluo1980@gmail.com
@johnnyluo1980

: Good evening, thanks for coming tonight. Before we start, let me introduce myself,why I am talking here? my name is Johnny Luo, I am an engineer here at Campaign Monitor. I work in platform team, we build distribute systems so our
: other product teams can build their product features on top of it. 
: By now I have been in Campaign Monitor for about three years now, in the last two years, we use golang to build quite a lot microservices which become part of the campaign monitor core systems.  We also have some battle scars with Kafka, so I think it will be good to share
: all these with you all, hope you take away something with you tonight.

* A little bit about myself


* What we are going to cover today
- About Kafka
- Producer
- Consumer
: This is what we are going to cover today,  first of all , I will give you a little bit introduction about kafka, it is quite important to understand some basic concept used in Kafka , if you want to use it well. 
: It is a golang meetup , and I love golang so ,of course we are going to talk about go . I will do some live demo about how to publish messages to Kafka, and how to consume from Kafka.

* What is Kafka ?
.link https://kafka.apache.org/ Apache Kafka
: how many of you run Kafka in your production environment? ok , Thank you very much.
: how many of you just play with Kafka before? 
- Kafka is a distributed messaging system, originally built at LinkedIn , and now it is  part of the Apache Software Foundation.
- Kafka is often used in big data , for data injection. 
: I give you an example, you have a web app / web site like us, you would like to collect all the web activities , like opens / clicks / page views etc, you might have 
: multiple consumers of these data, one service will consume these messages to show a live dashboard, antoher one might use it to aggregate data for analytics. 
- It usually run as a cluster on one or more servers, each server we call it a broker.
- Publish and subscribe to streams of records, similar to a message queue
- Store streams of records in a fault-tolerant durable way.
- Process streams of records as they occur.

* Kafka
- Producer
: Producer is an application or service that send messages to Kafka
: all messages produc
- Consumer
: Consumer is an applicatoin or service that get message from Kafka
.image producer_consumer.png
: the beauty of this design is , your producer can inject messages as fast as they want, and different consumers can consume message at their own speed.


* Kafka 
- Topic a topic can have multiple partitions
- Partition

.image log-anatomy.png
: all Kafka messages are organized into topics, if you wish to send a message to Kafka, you need to send it to a specfic topic, if you wish to read a message from Kafka, you need to read it from a topic,
: a Topic will have multiple partitions.  partitions are the actually log files. The position of each message in a partition, we call it offset

* Kafka
- Partition number is very important, because it will determinate how much parallelism you can achieve. Estimate your production traffic while choosing your partitions 
- Kafka guarantee at least once delivery, you need try your best to make sure consumer is idempotent.
- Order is guarantee at partition level
- Messages in Kafka topic is persistent , set your retention period accordingly 
: the longer you want to keep it in Kafka , the more disk space you will need.
- Make sure your replica is more than 1

* Kafka
When you decide to create a topic in kafka, you need to think about the following few questions.
- How many partitions in this topic?
- How long should I keep the record? (retention period)
- How many copies of the data should you keep? (replica)

* Kafka at Campaign Monitor
- We are running a 16 nodes Kafka cluster in AWS
- We publish events to Kafka from both MicroService, and (c#)Monolith
- so far we have about 1.5 billon events flow through our Kafka cluster every day.
: for a topic that doesn't have too much traffic , we set the partition number to 16, while a very busy topic, we set the partition to 64
: and we keep all the events for 20 days, and replica is 3

* Producer
Before you publish messages to Kafka topic, you need to ask yourself these questions
- Consistency 
- Availability 

: So what it means consistency, once you hand off your message to the library ,can you afford to lose the message? after you send the message to broker , if the broker get into trouble, and died, what behavour you expected?
: if one or the broker get into trouble, can you afford to lose message?  (unlean leader election)

* Producer 
- Sync Producer
 Sync Producer is easy to implement, and have stronger guarantee, but the performance won't be great
- Async Producer
 Async Producer will be much faster, it will need far more code to implement
- Trade off between consistency and throughput

: Sync producer means the library will send the message to Kafka broker before it return,while Async will buffer the messages you send to the library , and then flush to the broker on a interval
- ACK (WaitForLocal,WaitForAll)

* Producer
Live Demo
.image bluedemobutton.jpg 400 400

* Run kafka on your local machine
 go get -u github.com/johnnyluo/gokafka-workshop
 cd kafka-local
 docker-compose up -d
- We will be using Shopify/sarama library
 go get -u github.com/Shopify/sarama
 go get -u github.com/bsm/sarama-cluster


* Consumer
There are two types of consumer
- Partition consumer
- Cluster consumer

* Consumer
What is Partition Consumer? 
- Each Partition Consumer can only consume messages from one partition.
- You have to manage your own offsets

* Partition Consumer
Live Demo
.image bluedemobutton.jpg 400 400

* Cluster Consumer
- Consumer Group
- Competing consumer, each consumer will maintain a heartbeat with broker, when more consumer join the same consumer group, or some consumers get dropped out, broker will do rebalance , make sure no two consumers are reading from the same partition.
- Offsets is managed by Kafka using a special topic
 __consumer_offsets
- Client need to commit offsets, offsets are often commit async
- If you have many busy topics , you need to be careful of hotspot

* Cluster Consumer
Live Demo
.image bluedemobutton.jpg 400 400